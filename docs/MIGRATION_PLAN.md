# План постепенной миграции на новую архитектуру

## Принципы миграции

1. **Не ломаем работающий функционал** - все изменения должны быть обратно совместимы
2. **Параллельная работа** - новая и старая системы работают параллельно
3. **Постепенный переход** - мигрируем по частям с возможностью отката
4. **Feature flags** - новый функционал включается через флаги

## Этапы миграции

### Этап 1: Подготовка инфраструктуры (1-2 дня)
**Безопасно - не затрагивает текущий функционал**

1. ✅ Создать новые таблицы в отдельном файле `schema-v2.ts`
2. ✅ Создать AI сервисы в отдельных файлах
3. ✅ Создать сервис умного ранжирования
4. Создать миграции для новых таблиц (не трогая старые)
5. Добавить feature flags в `.env`:
   ```
   ENABLE_AI_PARSING=false
   ENABLE_SMART_RANKING=false
   ENABLE_NEW_PROFILE=false
   ```

### Этап 2: Параллельная работа (3-5 дней)
**Новый функционал работает параллельно со старым**

1. Создать новый endpoint `/api/v2/search` для AI-поиска
2. Создать команду `/newsearch` в боте для тестирования
3. При каждом поиске:
   - Сохранять в старую таблицу `profiles` (как сейчас)
   - Дублировать в новые таблицы `search_requests`
4. Логировать все расхождения для анализа

```typescript
// Пример параллельной работы
async function handleSearch(userId: string, params: any) {
  // Старая логика работает как обычно
  const oldResult = await oldSearchFlow(userId, params);
  
  // Новая логика в try-catch чтобы не сломать старую
  if (process.env.ENABLE_AI_PARSING === 'true') {
    try {
      const newResult = await newSearchFlow(userId, params);
      // Логируем расхождения
      logDifferences(oldResult, newResult);
    } catch (error) {
      logger.error('New search flow error:', error);
      // Продолжаем со старым результатом
    }
  }
  
  return oldResult;
}
```

### Этап 3: A/B тестирование (1 неделя)
**Постепенно включаем новый функционал для части пользователей**

1. Включить AI парсинг для 10% пользователей
2. Мониторить метрики:
   - Конверсия поиск → просмотр результатов
   - Количество уточняющих вопросов
   - Время до получения результатов
3. Постепенно увеличивать процент: 10% → 25% → 50% → 100%

```typescript
function shouldUseNewFlow(userId: string): boolean {
  if (process.env.ENABLE_AI_PARSING !== 'true') return false;
  
  // A/B тест по последней цифре userId
  const lastDigit = parseInt(userId.slice(-1));
  const percentage = parseInt(process.env.AI_PARSING_PERCENTAGE || '10');
  
  return lastDigit < (percentage / 10);
}
```

### Этап 4: Миграция данных (2-3 дня)
**Переносим исторические данные**

1. Скрипт миграции профилей:
   ```typescript
   // Разделяем старые profiles на user_profiles и search_requests
   async function migrateProfiles() {
     const oldProfiles = await db.select().from(profiles);
     
     for (const profile of oldProfiles) {
       // Создаем постоянный профиль
       await db.insert(userProfiles).values({
         userId: profile.userId,
         name: profile.name,
         departureCity: profile.departureCity,
         createdAt: profile.createdAt
       });
       
       // Последний поиск как search_request
       if (profile.countries || profile.budget) {
         await db.insert(searchRequests).values({
           userId: profile.userId,
           destination: profile.countries,
           budget: profile.budget,
           // ... остальные поля
         });
       }
     }
   }
   ```

2. Запускать миграцию батчами с проверками
3. Вести лог успешных/неуспешных миграций

### Этап 5: Переключение на новую систему (1 неделя)
**Плавный переход на новый функционал**

1. Переключить основной flow на новую систему
2. Оставить старую систему как fallback
3. Мониторить ошибки и откатываться при необходимости
4. Постепенно удалять старый код

### Этап 6: Cleanup (2-3 дня)
**Очистка после успешной миграции**

1. Удалить старые endpoints
2. Удалить неиспользуемый код
3. Архивировать старые таблицы
4. Обновить документацию

## Чек-лист безопасности

- [ ] Все новые таблицы имеют префикс v2_ или находятся в отдельной схеме
- [ ] Новый код не изменяет существующие таблицы
- [ ] Все новые функции обернуты в try-catch
- [ ] Feature flags позволяют мгновенно откатиться
- [ ] Ведется подробное логирование всех операций
- [ ] Есть скрипты для отката миграции
- [ ] Backup базы данных перед каждым этапом

## Мониторинг

### Ключевые метрики
- Количество успешных/неуспешных поисков
- Время ответа API
- Количество ошибок в логах
- Использование памяти/CPU
- Удовлетворенность пользователей (по обратной связи)

### Алерты
- Рост ошибок > 5% - автоматический откат
- Время ответа > 3 сек - investigation
- Падение конверсии > 10% - откат A/B теста

## Риски и митигация

| Риск | Вероятность | Влияние | Митигация |
|------|-------------|---------|-----------|
| Сломается текущий поиск | Низкая | Высокое | Feature flags, параллельная работа |
| Потеря данных при миграции | Низкая | Высокое | Backup, проверки, батчи |
| AI будет работать медленно | Средняя | Среднее | Кеширование, fallback на старую логику |
| Пользователи не поймут новый интерфейс | Средняя | Низкое | A/B тест, обучающие сообщения |

## Команда и ответственность

- **Разработка**: Основной разработчик
- **Тестирование**: QA + выборочные пользователи  
- **Мониторинг**: DevOps + разработчик
- **Принятие решений**: Product Owner

## Timeline

```
Неделя 1: Этап 1-2 (Подготовка + начало параллельной работы)
Неделя 2: Этап 3 (A/B тестирование)
Неделя 3: Этап 4-5 (Миграция данных + переключение)
Неделя 4: Этап 6 + стабилизация
```

## Критерии успеха

1. Ноль критических инцидентов
2. Конверсия поиск → бронирование выросла на 10%+
3. Среднее время до результата < 5 сек
4. 90% пользователей успешно используют AI поиск
5. Положительная обратная связь от пользователей